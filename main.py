#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¤– AI Memo Generator - æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è­°äº‹éŒ²ã‚’ç”Ÿæˆã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ„ãƒ¼ãƒ«
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime
from typing import Dict, Any, Optional

# ğŸ“š ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import requests

# ğŸ“ ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("ai_memo_generator")


class MemoGenerator:
    """ğŸ”„ æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è­°äº‹éŒ²ã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: str = "config.json"):
        """ğŸš€ åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.config_path = config_path
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """ğŸ“‚ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.error(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            # æœ€å°é™ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”ã™
            return {
                "llm": {
                    "provider": "openai",
                    "api_key": "",
                    "model": "gpt-4o-mini",
                    "temperature": 0.3,
                    "max_tokens": 1500
                },
                "templates": {
                    "default": "ä»¥ä¸‹ã¯ä¼šè­°ã®æ–‡å­—èµ·ã“ã—ã§ã™ã€‚ã“ã‚Œã‚’å…ƒã«è­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n{transcription}"
                }
            }
    
    def save_config(self):
        """ğŸ’¾ è¨­å®šã‚’ä¿å­˜"""
        try:
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(self.config, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {self.config_path}")
        except Exception as e:
            logger.error(f"âš ï¸ è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def generate_memo_from_file(self, input_file: str, output_file: Optional[str] = None) -> Optional[str]:
        """ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ã‚’èª­ã¿è¾¼ã¿ã€è­°äº‹éŒ²ã‚’ç”Ÿæˆ"""
        try:
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(input_file, "r", encoding="utf-8") as f:
                transcription = f.read()
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
            if output_file is None:
                base_name = os.path.splitext(input_file)[0]
                output_file = f"{base_name}_memo.txt"
            
            # è­°äº‹éŒ²ç”Ÿæˆ
            memo = self.generate_memo(transcription)
            
            if memo:
                # ç”Ÿæˆçµæœã®ä¿å­˜
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(memo)
                logger.info(f"âœ… è­°äº‹éŒ²ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
                return memo
            
            return None
        
        except FileNotFoundError:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
            return None
        except Exception as e:
            logger.error(f"âš ï¸ è­°äº‹éŒ²ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def generate_memo(self, transcription: str) -> Optional[str]:
        """ğŸ§  æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è­°äº‹éŒ²ã‚’ç”Ÿæˆ"""
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—
        template = self.config["templates"]["default"]
        prompt = template.replace("{transcription}", transcription)
        
        # LLM APIå‘¼ã³å‡ºã—
        provider = self.config["llm"]["provider"]
        logger.info(f"ğŸ”„ LLM API ({provider}) å‘¼ã³å‡ºã—é–‹å§‹")
        
        result = None
        if provider == "openai":
            result = self._call_openai_api(prompt)
        elif provider == "anthropic":
            result = self._call_anthropic_api(prompt)
        elif provider == "google":
            result = self._call_google_api(prompt)
        else:
            logger.error(f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider}")
            return None
        
        if result:
            logger.info(f"âœ… LLM API ({provider}) å‘¼ã³å‡ºã—å®Œäº†: ç´„{len(result)}æ–‡å­—ã®å¿œç­”ã‚’å—ä¿¡")
        else:
            logger.error(f"âŒ LLM API ({provider}) å‘¼ã³å‡ºã—å¤±æ•—: å¿œç­”ãªã—")
        
        return result
    
    def _call_openai_api(self, prompt: str) -> Optional[str]:
        """ğŸ”„ OpenAI APIã‚’å‘¼ã³å‡ºã™"""
        api_key = self.config["llm"]["api_key"]
        if not api_key:
            logger.error("ğŸ”‘ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None
        
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": self.config["llm"]["model"],
                "messages": [
                    {"role": "system", "content": "ã‚ãªãŸã¯ä¼šè­°ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ã‹ã‚‰è­°äº‹éŒ²ã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": self.config["llm"]["temperature"],
                "max_tokens": self.config["llm"]["max_tokens"]
            }
            
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                logger.error(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return None
        
        except Exception as e:
            logger.error(f"âš ï¸ OpenAI APIå‘¼ã³å‡ºã—ä¾‹å¤–: {e}")
            return None
    
    def _call_anthropic_api(self, prompt: str) -> Optional[str]:
        """ğŸ”„ Anthropic Claude APIã‚’å‘¼ã³å‡ºã™"""
        api_key = self.config["llm"]["api_key"]
        if not api_key:
            logger.error("ğŸ”‘ Anthropic APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None
        
        try:
            # Claude Messages APIå½¢å¼ã§å‘¼ã³å‡ºã—
            headers = {
                "Content-Type": "application/json",
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01"
            }
            
            data = {
                "model": self.config["llm"]["model"],
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": self.config["llm"]["temperature"],
                "max_tokens": self.config["llm"]["max_tokens"]
            }
            
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["content"][0]["text"]
            else:
                logger.error(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return None
        
        except Exception as e:
            logger.error(f"âš ï¸ Anthropic APIå‘¼ã³å‡ºã—ä¾‹å¤–: {e}")
            return None
    
    def _call_google_api(self, prompt: str) -> Optional[str]:
        """ğŸ”„ Google Gemini APIã‚’å‘¼ã³å‡ºã™"""
        api_key = self.config["llm"].get("google_api_key", "")
        if not api_key:
            logger.error("ğŸ”‘ Google APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None
        
        try:
            # ãƒ¢ãƒ‡ãƒ«åã«åŸºã¥ã„ã¦APIãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            model = self.config["llm"]["model"]
            model_id = model.replace("gemini-", "")
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_id}:generateContent?key={api_key}"
            
            headers = {
                "Content-Type": "application/json"
            }
            
            data = {
                "contents": [
                    {
                        "role": "user",
                        "parts": [{"text": prompt}]
                    }
                ],
                "generationConfig": {
                    "temperature": self.config["llm"]["temperature"],
                    "maxOutputTokens": self.config["llm"]["max_tokens"],
                    "topP": 0.95,
                    "topK": 40
                }
            }
            
            response = requests.post(url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                if "candidates" in result and len(result["candidates"]) > 0:
                    if "content" in result["candidates"][0]:
                        if "parts" in result["candidates"][0]["content"]:
                            text_parts = []
                            for part in result["candidates"][0]["content"]["parts"]:
                                if "text" in part:
                                    text_parts.append(part["text"])
                            return "".join(text_parts)
                
                logger.error(f"âŒ Google APIå¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
                return None
            else:
                logger.error(f"âŒ Google APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return None
        
        except Exception as e:
            logger.error(f"âš ï¸ Google APIå‘¼ã³å‡ºã—ä¾‹å¤–: {e}")
            return None
    
    def set_provider(self, provider: str):
        """ğŸ”§ LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¨­å®š"""
        if provider not in self.config.get("providers", {}):
            logger.warning(f"âš ï¸ æœªçŸ¥ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider}")
        self.config["llm"]["provider"] = provider
    
    def set_model(self, model: str):
        """ğŸ”§ LLMãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š"""
        provider = self.config["llm"]["provider"]
        models = self.config.get("providers", {}).get(provider, [])
        if models and model not in models:
            logger.warning(f"âš ï¸ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ '{provider}' ã§ã¯æœªçŸ¥ã®ãƒ¢ãƒ‡ãƒ«: {model}")
        self.config["llm"]["model"] = model
    
    def set_api_key(self, api_key: str):
        """ğŸ”‘ APIã‚­ãƒ¼ã‚’è¨­å®š"""
        self.config["llm"]["api_key"] = api_key
    
    def set_google_api_key(self, api_key: str):
        """ğŸ”‘ Google APIã‚­ãƒ¼ã‚’è¨­å®š"""
        self.config["llm"]["google_api_key"] = api_key
    
    def set_temperature(self, temperature: float):
        """ğŸŒ¡ï¸ temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š"""
        self.config["llm"]["temperature"] = max(0.0, min(1.0, temperature))
    
    def set_max_tokens(self, max_tokens: int):
        """ğŸ“ max_tokensãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š"""
        self.config["llm"]["max_tokens"] = max(1, max_tokens)
    
    def set_template(self, template_text: str):
        """ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¨­å®š"""
        self.config["templates"]["default"] = template_text


def parse_arguments():
    """ğŸ” ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹"""
    parser = argparse.ArgumentParser(description="ğŸ¤– AI Memo Generator - æ–‡å­—èµ·ã“ã—ã‹ã‚‰è­°äº‹éŒ²ã‚’ç”Ÿæˆ")
    
    parser.add_argument("--input", "-i", required=True, help="æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--output", "-o", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šinput_memo.txtï¼‰")
    parser.add_argument("--config", "-c", default="config.json", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--provider", "-p", help="LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆopenai/anthropic/googleï¼‰")
    parser.add_argument("--model", "-m", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å")
    parser.add_argument("--api-key", "-k", help="APIã‚­ãƒ¼")
    parser.add_argument("--google-api-key", "-gk", help="Google APIã‚­ãƒ¼ï¼ˆGoogleãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ä½¿ç”¨æ™‚ï¼‰")
    parser.add_argument("--temperature", "-t", type=float, help="Temperatureå€¤ï¼ˆ0.0ã€œ1.0ï¼‰")
    parser.add_argument("--max-tokens", "-mt", type=int, help="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°")
    
    return parser.parse_args()


def main():
    """ğŸš€ ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    # å¼•æ•°è§£æ
    args = parse_arguments()
    
    # åˆæœŸè¨­å®š
    generator = MemoGenerator(config_path=args.config)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰è¨­å®šã‚’ä¸Šæ›¸ã
    if args.provider:
        generator.set_provider(args.provider)
    
    if args.model:
        generator.set_model(args.model)
    
    if args.api_key:
        generator.set_api_key(args.api_key)
    
    if args.google_api_key:
        generator.set_google_api_key(args.google_api_key)
    
    if args.temperature is not None:
        generator.set_temperature(args.temperature)
    
    if args.max_tokens is not None:
        generator.set_max_tokens(args.max_tokens)
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if not os.path.isfile(args.input):
        logger.error(f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {args.input}")
        return 1
    
    # è­°äº‹éŒ²ç”Ÿæˆ
    result = generator.generate_memo_from_file(args.input, args.output)
    
    if result:
        print("âœ… è­°äº‹éŒ²ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        return 0
    else:
        print("âŒ è­°äº‹éŒ²ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())